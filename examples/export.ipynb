{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51769646",
   "metadata": {},
   "source": [
    "# Generate a C export for the GBA\n",
    "If you have trained model in onnx, you can generate a c export of inference for the gba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d3e066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnx import shape_inference\n",
    "from onnx import numpy_helper\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pkmn_rl_arena.quantize.quantize import FullQuantizer\n",
    "from pkmn_rl_arena.export.onnx_exporter import ONNXExporter\n",
    "from pkmn_rl_arena.paths import PATHS\n",
    "\n",
    "from pkmn_rl_arena.export.passes.delete_pass import (\n",
    "    DeleteFirstInputQDQPass,\n",
    "    DeleteQuantizePass,\n",
    "    DeleteFirstLastQuantizeDequantizePass,\n",
    ")\n",
    "from pkmn_rl_arena.export.passes.fusion_pass import (\n",
    "    GemmQuantDequantFusionPass,\n",
    ")\n",
    "\n",
    "from pkmn_rl_arena.export.base import ExportBaseGba\n",
    "from pkmn_rl_arena.export.onnx_utils import OnnxUtils\n",
    "from pkmn_rl_arena.data.parser import MapAnalyzer\n",
    "\n",
    "from pkmn_rl_arena.export.exporters.parameters import ExportParameters\n",
    "import rustboyadvance_py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe0918",
   "metadata": {},
   "source": [
    "### Set Path\n",
    "We need three paths : \n",
    "- The regular onnx, the one that we trained before \n",
    "- The quantized one, used to run an inference with onnx_runtime and compare oiur results \n",
    "- The fused one, from the quantized model, we create a custom model wich fuse Gemm and QDQ, to be interpretable by our export module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4990bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = \"pokemon_battle_model.onnx\"\n",
    "quantized_onnx_path = \"pokemon_battle_model_quantized.onnx\"\n",
    "fused_path = \"pokemon_battle_model_quantized_fused.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf4b16",
   "metadata": {},
   "source": [
    "You can print the actual graph with onnx to see how much we manipulate it ;) (But it's better with netron, a tool to vizualize onnx graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c622af98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph main_graph (\n",
      "  %input[FLOAT, 1x360]\n",
      ") initializers (\n",
      "  %net.0.weight[FLOAT, 128x360]\n",
      "  %net.0.bias[FLOAT, 128]\n",
      "  %net.2.weight[FLOAT, 10x128]\n",
      "  %net.2.bias[FLOAT, 10]\n",
      ") {\n",
      "  %/net/net.0/Gemm_output_0 = Gemm[alpha = 1, beta = 1, transB = 1](%input, %net.0.weight, %net.0.bias)\n",
      "  %/net/net.1/Relu_output_0 = Relu(%/net/net.0/Gemm_output_0)\n",
      "  %output = Gemm[alpha = 1, beta = 1, transB = 1](%/net/net.1/Relu_output_0, %net.2.weight, %net.2.bias)\n",
      "  return %output\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "onnx_raw = onnx.load(onnx_path)\n",
    "print(onnx.helper.printable_graph(onnx_raw.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d964fd6b",
   "metadata": {},
   "source": [
    "### Quantize the model \n",
    "To quantize our model, we need to calibrate QDQ pairs, to do so, calibration data is needed\n",
    "\n",
    "> Note : \n",
    "> It's better to calibrate data, with real data. In the next version of our project, a tool to generate calibration data will be available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec996992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph main_graph (\n",
      "  %input[FLOAT, 1x360]\n",
      ") initializers (\n",
      "  %input_zero_point[INT8, scalar]\n",
      "  %input_scale[FLOAT, scalar]\n",
      "  %/net/net.0/Gemm_output_0_zero_point[INT8, scalar]\n",
      "  %/net/net.0/Gemm_output_0_scale[FLOAT, scalar]\n",
      "  %net.0.weight_zero_point[INT8, scalar]\n",
      "  %net.0.weight_scale[FLOAT, scalar]\n",
      "  %net.0.weight_quantized[INT8, 128x360]\n",
      "  %/net/net.1/Relu_output_0_zero_point[INT8, scalar]\n",
      "  %/net/net.1/Relu_output_0_scale[FLOAT, scalar]\n",
      "  %output_zero_point[INT8, scalar]\n",
      "  %output_scale[FLOAT, scalar]\n",
      "  %net.2.weight_zero_point[INT8, scalar]\n",
      "  %net.2.weight_scale[FLOAT, scalar]\n",
      "  %net.2.weight_quantized[INT8, 10x128]\n",
      "  %net.0.bias_quantized[INT32, 128]\n",
      "  %net.0.bias_quantized_scale[FLOAT, 1]\n",
      "  %net.0.bias_quantized_zero_point[INT32, scalar]\n",
      "  %net.2.bias_quantized[INT32, 10]\n",
      "  %net.2.bias_quantized_scale[FLOAT, 1]\n",
      "  %net.2.bias_quantized_zero_point[INT32, scalar]\n",
      ") {\n",
      "  %input_QuantizeLinear_Output = QuantizeLinear(%input, %input_scale, %input_zero_point)\n",
      "  %net.0.bias = DequantizeLinear(%net.0.bias_quantized, %net.0.bias_quantized_scale, %net.0.bias_quantized_zero_point)\n",
      "  %net.0.weight_DequantizeLinear_Output = DequantizeLinear(%net.0.weight_quantized, %net.0.weight_scale, %net.0.weight_zero_point)\n",
      "  %net.2.bias = DequantizeLinear(%net.2.bias_quantized, %net.2.bias_quantized_scale, %net.2.bias_quantized_zero_point)\n",
      "  %net.2.weight_DequantizeLinear_Output = DequantizeLinear(%net.2.weight_quantized, %net.2.weight_scale, %net.2.weight_zero_point)\n",
      "  %input_DequantizeLinear_Output = DequantizeLinear(%input_QuantizeLinear_Output, %input_scale, %input_zero_point)\n",
      "  %/net/net.0/Gemm_output_0 = Gemm[alpha = 1, beta = 1, transB = 1](%input_DequantizeLinear_Output, %net.0.weight_DequantizeLinear_Output, %net.0.bias)\n",
      "  %/net/net.0/Gemm_output_0_QuantizeLinear_Output = QuantizeLinear(%/net/net.0/Gemm_output_0, %/net/net.0/Gemm_output_0_scale, %/net/net.0/Gemm_output_0_zero_point)\n",
      "  %/net/net.0/Gemm_output_0_DequantizeLinear_Output = DequantizeLinear(%/net/net.0/Gemm_output_0_QuantizeLinear_Output, %/net/net.0/Gemm_output_0_scale, %/net/net.0/Gemm_output_0_zero_point)\n",
      "  %/net/net.1/Relu_output_0 = Relu(%/net/net.0/Gemm_output_0_DequantizeLinear_Output)\n",
      "  %/net/net.1/Relu_output_0_QuantizeLinear_Output = QuantizeLinear(%/net/net.1/Relu_output_0, %/net/net.1/Relu_output_0_scale, %/net/net.1/Relu_output_0_zero_point)\n",
      "  %/net/net.1/Relu_output_0_DequantizeLinear_Output = DequantizeLinear(%/net/net.1/Relu_output_0_QuantizeLinear_Output, %/net/net.1/Relu_output_0_scale, %/net/net.1/Relu_output_0_zero_point)\n",
      "  %output_QuantizeLinear_Input = Gemm[alpha = 1, beta = 1, transB = 1](%/net/net.1/Relu_output_0_DequantizeLinear_Output, %net.2.weight_DequantizeLinear_Output, %net.2.bias)\n",
      "  %output_QuantizeLinear_Output = QuantizeLinear(%output_QuantizeLinear_Input, %output_scale, %output_zero_point)\n",
      "  %output = DequantizeLinear(%output_QuantizeLinear_Output, %output_scale, %output_zero_point)\n",
      "  return %output\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_samples = 10\n",
    "\n",
    "quantizer = FullQuantizer(onnx_path, quantized_onnx_path)\n",
    "calib_reader = FullQuantizer.create_fake_calibration_data(\n",
    "    onnx_path, num_samples=num_samples\n",
    ")\n",
    "quantizer.quantize(calib_reader)\n",
    "\n",
    "# Infer shapes\n",
    "quantized_model = onnx.load(quantized_onnx_path)\n",
    "inferred_model = shape_inference.infer_shapes(quantized_model)\n",
    "onnx.save(inferred_model, quantized_onnx_path)\n",
    "\n",
    "print(onnx.helper.printable_graph(inferred_model.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f214a6",
   "metadata": {},
   "source": [
    "### Get the GBA template folder\n",
    "To tests our export, a GBA folder is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79c54d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./gba'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ExportBaseGba.copy_gba_folder(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee05973f",
   "metadata": {},
   "source": [
    "### Generating random inputs\n",
    "To test our exported model, we generate random inputs and infer it both with onnx_runtime and our model.\n",
    "\n",
    "But our exported model and our onnx are different, one use QDQ pair and the other is full int8, so we need to retrive our input and output scaling factors to put results on the right range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "844b2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = onnx.load(quantized_onnx_path)\n",
    "output_scale = OnnxUtils.get_last_qdq_scaling_factor(quantized_model.graph)[0]\n",
    "input_scale = OnnxUtils.get_first_qdq_scaling_factor(quantized_model.graph)[0]\n",
    "\n",
    "input_random = np.random.uniform(-1, 1, (1, 360)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad65c1c",
   "metadata": {},
   "source": [
    "Then we run the inference with onnx_runtime and get the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4be48a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Runtime output: [[0.57719505 0.44138443 0.3395265  0.30557385 0.23766854 0.16976325\n",
      "  0.44138443 0.10185795 0.44138443 0.40743178]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ort_session = ort.InferenceSession(quantized_onnx_path)\n",
    "input_type = ort_session.get_inputs()[0].type\n",
    "if 'int8' in input_type:\n",
    "    model_input = input_random\n",
    "else:\n",
    "    model_input = input_random.astype(np.float32)\n",
    "ort_outputs = ort_session.run(None, {ort_session.get_inputs()[0].name: model_input})\n",
    "onnx_output = ort_outputs[0]\n",
    "print(\"ONNX Runtime output:\", onnx_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4cb54",
   "metadata": {},
   "source": [
    "### Fuse and delete nodes\n",
    "To have model intrepretable by our export module, we need to fuse QDQ pairs and Gemm OP, it creates a QGemmCustom. It makes the graph more understandable, and we generate Gemm and QDQ as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbcbc77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting QuantizeLinear -> DequantizeLinear pair: input_QuantizeLinear -> input_DequantizeLinear\n",
      "Deleting QuantizeLinear -> DequantizeLinear pair: /net/net.1/Relu_output_0_QuantizeLinear -> /net/net.1/Relu_output_0_DequantizeLinear\n",
      "Remapped input: input_DequantizeLinear_Output -> input in node /net/net.0/Gemm_fused\n",
      "Remapped input: /net/net.1/Relu_output_0_DequantizeLinear_Output -> /net/net.1/Relu_output_0 in node /net/net.2/Gemm_fused\n",
      "graph main_graph (\n",
      "  %input[FLOAT, 1x360]\n",
      ") initializers (\n",
      "  %input_zero_point[INT8, scalar]\n",
      "  %input_scale[FLOAT, scalar]\n",
      "  %/net/net.0/Gemm_output_0_zero_point[INT8, scalar]\n",
      "  %/net/net.0/Gemm_output_0_scale[FLOAT, scalar]\n",
      "  %net.0.weight_zero_point[INT8, scalar]\n",
      "  %net.0.weight_scale[FLOAT, scalar]\n",
      "  %net.0.weight_quantized[INT8, 128x360]\n",
      "  %/net/net.1/Relu_output_0_zero_point[INT8, scalar]\n",
      "  %/net/net.1/Relu_output_0_scale[FLOAT, scalar]\n",
      "  %output_zero_point[INT8, scalar]\n",
      "  %output_scale[FLOAT, scalar]\n",
      "  %net.2.weight_zero_point[INT8, scalar]\n",
      "  %net.2.weight_scale[FLOAT, scalar]\n",
      "  %net.2.weight_quantized[INT8, 10x128]\n",
      "  %net.0.bias_quantized[INT32, 128]\n",
      "  %net.0.bias_quantized_scale[FLOAT, 1]\n",
      "  %net.0.bias_quantized_zero_point[INT32, scalar]\n",
      "  %net.2.bias_quantized[INT32, 10]\n",
      "  %net.2.bias_quantized_scale[FLOAT, 1]\n",
      "  %net.2.bias_quantized_zero_point[INT32, scalar]\n",
      ") {\n",
      "  %net.0.bias = DequantizeLinear(%net.0.bias_quantized, %net.0.bias_quantized_scale, %net.0.bias_quantized_zero_point)\n",
      "  %net.0.weight_DequantizeLinear_Output = DequantizeLinear(%net.0.weight_quantized, %net.0.weight_scale, %net.0.weight_zero_point)\n",
      "  %net.2.bias = DequantizeLinear(%net.2.bias_quantized, %net.2.bias_quantized_scale, %net.2.bias_quantized_zero_point)\n",
      "  %net.2.weight_DequantizeLinear_Output = DequantizeLinear(%net.2.weight_quantized, %net.2.weight_scale, %net.2.weight_zero_point)\n",
      "  %/net/net.1/Relu_output_0 = Relu(%/net/net.0/Gemm_output_0_DequantizeLinear_Output)\n",
      "  %/net/net.0/Gemm_output_0_DequantizeLinear_Output = QGemmCustom[alpha = 1, beta = 1, transB = 1](%input, %net.0.weight_DequantizeLinear_Output, %net.0.bias, %/net/net.0/Gemm_output_0_scale, %/net/net.0/Gemm_output_0_zero_point, %/net/net.0/Gemm_output_0_scale, %/net/net.0/Gemm_output_0_zero_point)\n",
      "  %output = QGemmCustom[alpha = 1, beta = 1, transB = 1](%/net/net.1/Relu_output_0, %net.2.weight_DequantizeLinear_Output, %net.2.bias, %output_scale, %output_zero_point, %output_scale, %output_zero_point)\n",
      "  return %output\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "fusion_pass = GemmQuantDequantFusionPass()\n",
    "delete_pass = DeleteQuantizePass()\n",
    "\n",
    "fusion_pass.run(quantized_model.graph)\n",
    "delete_pass.run(quantized_model.graph)\n",
    "onnx.save(quantized_model, fused_path)\n",
    "\n",
    "fused_model = onnx.load(fused_path)\n",
    "print(onnx.helper.printable_graph(fused_model.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4ac18",
   "metadata": {},
   "source": [
    "### Generate the export\n",
    "To generate the export we just need to call a function. We generate includes, which contains headers with all of the parameters (weights and bias). And a forward.c which do ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af95709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported QGemm layer parameters for _NET_NET_0_GEMM_FUSED\n",
      "Exported layer _NET_NET_0_GEMM_FUSED parameters to gba/include\n",
      "Exported layer _NET_NET_1_RELU parameters to gba/include\n",
      "Exported QGemm layer parameters for _NET_NET_2_GEMM_FUSED\n",
      "Exported layer _NET_NET_2_GEMM_FUSED parameters to gba/include\n",
      "Forward function exported to: gba/source/forward.c\n",
      "Forward function header exported to: gba/include/forward.h\n"
     ]
    }
   ],
   "source": [
    "exporter = ONNXExporter(fused_path)\n",
    "exporter.export(output_dir=\"gba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31edf2d",
   "metadata": {},
   "source": [
    "### Make the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1d37489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba'\n",
      "forward.c\n",
      "template.c\n",
      "linking cartridge\n",
      "built ... gba.gba\n",
      "ROM fixed!\n",
      "make: Leaving directory '/home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from /home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/include/forward.h:5,\n",
      "                 from /home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/source/forward.c:5:\n",
      "/home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/include/nn_functions.h:28:24: warning: 'weight_buffer' defined but not used [-Wunused-variable]\n",
      "   28 | IN_IWRAM static int8_t weight_buffer[WEIGHT_BUFFER_BYTES] __attribute__((aligned(4)));\n",
      "      |                        ^~~~~~~~~~~~~\n",
      "In file included from /home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/source/template.c:9:\n",
      "/home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/include/tests.h: In function 'all_tests':\n",
      "/home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/include/tests.h:428:9: warning: variable 'start_time' set but not used [-Wunused-but-set-variable]\n",
      "  428 |     u32 start_time, end_time, result;\n",
      "      |         ^~~~~~~~~~\n",
      "/home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/source/template.c: In function 'main':\n",
      "/home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/source/template.c:41:17: warning: passing argument 1 of 'forward' discards 'volatile' qualifier from pointer target type [-Wdiscarded-qualifiers]\n",
      "   41 |         forward(input, output);\n",
      "      |                 ^~~~~\n",
      "In file included from /home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/source/template.c:13:\n",
      "/home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/include/forward.h:7:22: note: expected 'int8_t *' {aka 'signed char *'} but argument is of type 'volatile int8_t *' {aka 'volatile signed char *'}\n",
      "    7 | void forward(int8_t *input, int8_t *output);\n",
      "      |              ~~~~~~~~^~~~~\n",
      "/home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/source/template.c:41:24: warning: passing argument 2 of 'forward' discards 'volatile' qualifier from pointer target type [-Wdiscarded-qualifiers]\n",
      "   41 |         forward(input, output);\n",
      "      |                        ^~~~~~\n",
      "/home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/include/forward.h:7:37: note: expected 'int8_t *' {aka 'signed char *'} but argument is of type 'volatile int8_t *' {aka 'volatile signed char *'}\n",
      "    7 | void forward(int8_t *input, int8_t *output);\n",
      "      |                             ~~~~~~~~^~~~~~\n",
      "In file included from /home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/include/forward.h:5:\n",
      "/home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/include/nn_functions.h: At top level:\n",
      "/home/wboussella/Documents/rl_new_pokemon_ai/rl_new_pokemon_ai/examples/gba/include/nn_functions.h:28:24: warning: 'weight_buffer' defined but not used [-Wunused-variable]\n",
      "   28 | IN_IWRAM static int8_t weight_buffer[WEIGHT_BUFFER_BYTES] __attribute__((aligned(4)));\n",
      "      |                        ^~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"make -C gba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b171dcf",
   "metadata": {},
   "source": [
    "### Communicate with the rust emulator\n",
    "To run the emulator, we need to add stop addrs, write inside the input and read the output. To understand how it works, please refer to our well writed tutorial on how interragir with the emulator.\n",
    "\n",
    "https://github.com/wissammm/PkmnRLArena/wiki/How-stopHandleTurn-works\n",
    "```c\n",
    "volatile u16 stopWriteData IN_EWRAM;\n",
    "volatile u16 stopReadData IN_EWRAM;\n",
    "volatile int8_t input[1024] IN_EWRAM;\n",
    "volatile int8_t output[10] IN_EWRAM;\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "    ...\n",
    "    stopWriteData = 1;\n",
    "    forward(input, output);\n",
    "    stopReadData = 1;\n",
    "    ...\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8862023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_gba_environment(rom_path, map_path):\n",
    "    \"\"\"Setup GBA environment and return necessary objects.\"\"\"\n",
    "    gba = rustboyadvance_py.RustGba()\n",
    "    gba.load(PATHS[\"BIOS\"], rom_path)\n",
    "    parser = MapAnalyzer(map_path)\n",
    "    addr_write = int(parser.get_address(\"stopWriteData\"), 16)\n",
    "    addr_read = int(parser.get_address(\"stopReadData\"), 16)\n",
    "    gba.add_stop_addr(addr_write, 1, True, \"stopWriteData\", 3)\n",
    "    gba.add_stop_addr(addr_read, 1, True, \"stopReadData\", 4)\n",
    "\n",
    "    output_addr = int(parser.get_address(\"output\"), 16)\n",
    "    input_addr = int(parser.get_address(\"input\"), 16)\n",
    "\n",
    "    return gba, parser, addr_write, addr_read, output_addr, input_addr\n",
    "\n",
    "\n",
    "def run_gba_inference(\n",
    "    gba, addr_write, input_addr, output_addr, input_data, output_size\n",
    "):\n",
    "    \"\"\"Run inference on GBA and return results.\"\"\"\n",
    "    # Wait for initial stop\n",
    "    id = gba.run_to_next_stop(20000)\n",
    "    while id != 3:\n",
    "        id = gba.run_to_next_stop(20000)\n",
    "\n",
    "    # Write input data\n",
    "    gba.write_i8_list(input_addr, input_data.reshape(-1).tolist())\n",
    "    gba.write_u16(addr_write, 0)\n",
    "\n",
    "    # Wait for computation to complete\n",
    "    id = gba.run_to_next_stop(20000)\n",
    "    while id != 4:\n",
    "        id = gba.run_to_next_stop(20000)\n",
    "\n",
    "    # Read output\n",
    "    output_read = gba.read_i8_list(output_addr, output_size)\n",
    "    return np.array(output_read, dtype=np.int8).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d78e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;208mWARN\u001b[0m [rustboyadvance_utils::elf] \u001b[1;38;5;208mELF: skipping program header ProgramHeader { p_type: \"PT_LOAD\", p_flags: 0x6, p_offset: 0xb8, p_vaddr: 0x30000b8, p_paddr: 0x30000b8, p_filesz: 0x0, p_memsz: 0x464, p_align: 4096 }\u001b[0m\n",
      "INFO [rustboyadvance_utils::elf] ELF: loading segment phdr: ProgramHeader { p_type: \"PT_LOAD\", p_flags: 0x5, p_offset: 0x1000, p_vaddr: 0x8000000, p_paddr: 0x8000000, p_filesz: 0x22b50, p_memsz: 0x22b50, p_align: 4096 } range 0x1000..0x23b50 vec range 0x8000000..0x8022b50\n",
      "INFO [rustboyadvance_utils::elf] ELF: loading segment phdr: ProgramHeader { p_type: \"PT_LOAD\", p_flags: 0x5, p_offset: 0x24000, p_vaddr: 0x3000000, p_paddr: 0x8022b50, p_filesz: 0xb8, p_memsz: 0xb8, p_align: 4096 } range 0x24000..0x240b8 vec range 0x8022b50..0x8022c08\n",
      "INFO [rustboyadvance_utils::elf] ELF: loading segment phdr: ProgramHeader { p_type: \"PT_LOAD\", p_flags: 0x6, p_offset: 0x2451c, p_vaddr: 0x300051c, p_paddr: 0x8022c08, p_filesz: 0x176c, p_memsz: 0x176c, p_align: 4096 } range 0x2451c..0x25c88 vec range 0x8022c08..0x8024374\n",
      "INFO [rustboyadvance_utils::elf] ELF: loading segment phdr: ProgramHeader { p_type: \"PT_LOAD\", p_flags: 0x6, p_offset: 0x26000, p_vaddr: 0x2000000, p_paddr: 0x8024374, p_filesz: 0x630, p_memsz: 0x630, p_align: 4096 } range 0x26000..0x26630 vec range 0x8024374..0x80249a4\n",
      "INFO [rustboyadvance_utils::elf] ELF: loading segment phdr: ProgramHeader { p_type: \"PT_LOAD\", p_flags: 0x4, p_offset: 0x26630, p_vaddr: 0x2000630, p_paddr: 0x80249a4, p_filesz: 0x8, p_memsz: 0x8, p_align: 4096 } range 0x26630..0x26638 vec range 0x80249a4..0x80249ac\n",
      "INFO [rustboyadvance_core::cartridge::builder] Loaded ROM: CartridgeHeader { game_title: \"\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\", game_code: \"\\0\\0\\0\\0\", maker_code: \"01\", software_version: 0, checksum: 240 }\n",
      "\u001b[1;38;5;208mWARN\u001b[0m [rustboyadvance_core::cartridge::builder] \u001b[1;38;5;208mcould not detect backup save type\u001b[0m\n",
      "\u001b[1;38;5;208mWARN\u001b[0m [rustboyadvance_core::gba] \u001b[1;38;5;208mThis is not the real bios rom, some games may not be compatible\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding stop address: addr=33554976, value=1, is_active=true, name=stopWriteData, id=3\n",
      "Adding stop address: addr=33554978, value=1, is_active=true, name=stopReadData, id=4\n",
      "ONNX output (int8): [[0.57719505 0.44138443 0.3395265  0.30557385 0.23766854 0.16976325\n",
      "  0.44138443 0.10185795 0.44138443 0.40743178]]\n",
      "GBA output (int8): [ 6 23 -1 11 17 11 11  5  2 19]\n",
      "ONNX output (float): [[0.57719505 0.44138443 0.3395265  0.30557385 0.23766854 0.16976325\n",
      "  0.44138443 0.10185795 0.44138443 0.40743178]]\n",
      "GBA output (float): [ 0.20371589  0.78091097 -0.03395265  0.37347916  0.57719505  0.37347916\n",
      "  0.37347916  0.16976325  0.0679053   0.64510036]\n",
      "Dequantized outputs match within tolerance!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO [rustboyadvance_core::sound] bias - setting sample frequency to 32768hz\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAverage difference: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_diff\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDifferences: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m.assertTrue(float_match, \u001b[33m\"\u001b[39m\u001b[33mOutputs don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt match even after dequantization\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "gba, parser, addr_write, addr_read, output_addr, input_addr = (\n",
    "    setup_gba_environment(\"gba/gba.elf\", \"gba/build/gba.map\")\n",
    ")\n",
    "input_gba = np.round(input_random / input_scale).astype(np.int8)\n",
    "gba_output = run_gba_inference(gba, addr_write, input_addr, output_addr, \n",
    "                            input_gba, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c426ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ONNX output (int8): {onnx_output}\")\n",
    "print(f\"GBA output (int8): {gba_output}\")\n",
    "onnx_float = onnx_output.astype(np.float32)\n",
    "gba_float = (gba_output.astype(np.float32)) * output_scale\n",
    "print(f\"ONNX output (float): {onnx_float}\")\n",
    "print(f\"GBA output (float): {gba_float}\")\n",
    "float_match = np.allclose(onnx_float, gba_float, rtol=1e-1, atol=6e4)\n",
    "if float_match:\n",
    "    print(\"Dequantized outputs match within tolerance!\")\n",
    "else:\n",
    "    print(\"Dequantized outputs don't match\")\n",
    "    diff = np.abs(onnx_float - gba_float)\n",
    "    max_diff = np.max(diff)\n",
    "    avg_diff = np.mean(diff)\n",
    "    print(f\"Max difference: {max_diff}\")\n",
    "    print(f\"Average difference: {avg_diff}\")\n",
    "    print(f\"Differences: {diff}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pkmn-rl-arena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
